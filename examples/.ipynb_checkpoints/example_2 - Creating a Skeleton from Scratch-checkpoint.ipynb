{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Creating a large assembly from scratch is time consuming, therefore, a selection on classes have been provided within BOM analysis to parse a skeleton which can be loaded into an assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokamak Parts\n",
    "Parts contains the parts which will build the skeleton. Every part has a type and a reference, the type is the key in the part dictionary. The reference (called by .ref) is analogous to a part number which should be unique to that part. The parts can be split across multiple files or dictionaries that will be read into a single skeleton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = {\n",
    "    \"assembly\": {\n",
    "        \"class_str\": [\"bom_analysis.bom.Assembly\"],\n",
    "        \"params_name\": [\"assembly\"],\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"class_str\": [\"bom_analysis.bom.Component\"],\n",
    "        \"params_name\": [\"component\"],\n",
    "    },\n",
    "}\n",
    "tokamak_parts = {\n",
    "    \"blanket\": {\n",
    "        \"inherits\": [\"assembly\"],\n",
    "        \"children\": {\n",
    "            \"breeding_zone\": {\"type\": \"breeding_pins\"},\n",
    "            \"manifold\": {\"type\": \"double_wall_mf\"},\n",
    "        },\n",
    "    },\n",
    "    \"breeding_pins\": {\n",
    "        \"inherits\": [\"component\"],\n",
    "        \"test_list\": [\"hello\"],\n",
    "        \"params_name\": [\"pins\"],\n",
    "    },\n",
    "    \"double_wall_mf\": {\"inherits\": [\"component\"], \"material\": {\"name\": \"steel\"}},\n",
    "}\n",
    "extra_info = {\n",
    "    \"double_wall_mf\": {\"description\": \"a manifold with a double wall\"},\n",
    "    \"breeding_pins\": {\"test_list\": [\"world\"]},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionaries can be merged together using normal methods or with the UpdateDict class in framework.utils. UpdateDict aims to allow nested updates of dictionaries, lists etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom_analysis.utils import UpdateDict\n",
    "import pprint\n",
    "\n",
    "UpdateDict(tokamak_parts, parts, extra_info)\n",
    "pprint.pprint(tokamak_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the lists are merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing\n",
    "The dictionaries (defined or loaded in from files) can then be parsed together to form a full skeleton based on the above imporant keys\n",
    "\n",
    "There are some important strings in these dictionaries.\n",
    "\n",
    "* \"inherits\" - the strings in this list will be searched for within any part dictionaries and the dictionary from the item that is inherited from will be merged\n",
    "* \"class_str\" - string within class_str list will be used to create the classes from strings. In-built can be passed.\n",
    "* \"children\" - defines lower level in the hierarchy with the keys in the dict becoming and the \"type\" being used to search the parts\n",
    "* \"params_name\" - it is optional but a set of parameters can also be loaded into the skeleton by specifying a key to their dictionary in params_name\n",
    "\n",
    "The created skeleton is written to the skeleton attribute of the SkeletonParser instance. For this example, each stage of parsing related to the above strings will be taken individually. In the end, a method will be given that handles everything for the user.\n",
    "\n",
    "To create a skeleton, the type and reference of the component at the top of the hierarchy are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom_analysis.parsers import SkeletonParser\n",
    "\n",
    "parsed = SkeletonParser()\n",
    "\n",
    "parsed.spine(\n",
    "    component_ref=\"my_new_blanket\",\n",
    "    component_type=\"blanket\",\n",
    "    component_database=tokamak_parts,\n",
    ")\n",
    "\n",
    "pprint.pprint(parsed.skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the required components are now shown in the skeleton with the references acting as keys. Some metadata has been added on the top reference and type to aid with loading in the future.\n",
    "\n",
    "The components can then be inherited and the parameters added. For the parameters, dictionary of is needed with the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"component\": {\n",
    "        \"mass\": {\"var\": \"mass\", \"description\": \"the mass of the component\"},\n",
    "        \"temperature\": {\n",
    "            \"var\": \"temperature\",\n",
    "            \"description\": \"the component temperature\",\n",
    "        },\n",
    "    },\n",
    "    \"assembly\": {\n",
    "        \"envelope_volume\": {\n",
    "            \"var\": \"envelope_volume\",\n",
    "            \"description\": \"the volumetric envelope occupied by the assembly\",\n",
    "        }\n",
    "    },\n",
    "    \"pins\": {\"diameter\": {\"var\": \"diameter\", \"description\": \"the diameter of the pin\"}},\n",
    "}\n",
    "\n",
    "parsed.add_bones(tokamak_parts, parameters)\n",
    "pprint.pprint(parsed.skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it can be seen that the params_name and inherits have been removed and replaced with _params and inherited.\n",
    "\n",
    "This process can be replicated again with the component dictionary method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_parsed = SkeletonParser()\n",
    "new_parsed.component_dictionary(\n",
    "    component_ref=\"my_second_blanket\",\n",
    "    component_type=\"blanket\",\n",
    "    component_database=tokamak_parts,\n",
    "    parameter_dictionary=parameters,\n",
    ")\n",
    "pprint.pprint(new_parsed.skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can then easily be loaded into an assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom_analysis import Assembly\n",
    "\n",
    "first_blanket = Assembly()\n",
    "first_blanket.from_dict(parsed.skeleton)\n",
    "second_blanket = Assembly()\n",
    "second_blanket.from_dict(new_parsed.skeleton)\n",
    "print(first_blanket.params)\n",
    "print(first_blanket.params.envelope_volume)\n",
    "print(second_blanket.manifold.material)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "There are two extra examples on the parsing of skeletons, one which uses the Config to repeat what has been done in this example and one which updates the skeleton using a settings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
