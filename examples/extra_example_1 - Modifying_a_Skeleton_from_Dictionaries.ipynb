{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "It may be necessary to modify a skeleton from that created in with a Config. This could include the changing of parts, the application of default parameters, and/or the expansion of datastructures.\n",
    "\n",
    "First off, the skeleton that was created in example_1 can be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import pprint\n",
    "from bom_analysis.base import BaseConfig as Config\n",
    "\n",
    "Config.define_config(config_path=\"./files/example_config.json\")\n",
    "\n",
    "with open(Path(\"example_Creating_a_Skeleton_from_Settings.json\"), \"r\") as f:\n",
    "    loaded_skeleton = json.load(f)\n",
    "pprint.pprint(loaded_skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying a Skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the skeleton is loaded it can be edited. This can be done by passing it a settings dictionary to the SettingsParser. \n",
    "\n",
    "The best way to look at the SettingsParser is that it has found the bones of a skeleton laid out in the ground and is now rearranging them, adding new bones, and adding new features to the bones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom_analysis.parsers import SettingsParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SettingsParser can be given a number of special keys as strings - the input of which can be checked. These keys are:\n",
    "* \"part_changes\" - the swapping out of parts in the skeleton my modifying the children\n",
    "* \"other_changes\" - non-structural changes to the skeleton\n",
    "* \"top\" - as in config, (the value of which will be defaulted to) top defines the top of the heirarchy\n",
    "* \"parts\" - as in config, allows the supply of new .jsons containing parts for the skeleton\n",
    "* \"modules\" - the assessment modules a skeleton will undergo. In this example, the running of these modules will not be shown but they can be used to add features to the skeleton\n",
    "* \"materials\" - the materials which will make up the componet. It is necessary to specify as a check is run to see if material exists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying Top\n",
    "The top of the hierarchy can be changed but to do so the parts must be supplied as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows the skeleton top to be restructured. It is more likely that instead of changing the top level component, other component changes will be made. \n",
    "\n",
    "\"part_changes\" and \"other_changes\" just work by altering the dictionary and, therefore, should be set like this in the settings.\n",
    "\n",
    "### Making Part Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making part changes can happen within the code by supplying the required information to the parser, or following initialisation and modification of the parser. This is switched by the operate optional input.\n",
    "\n",
    "*operate*\n",
    "> bolean whether rebuild the skeleton with the part changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = copy.deepcopy(loaded_skeleton)\n",
    "\n",
    "settings = {\n",
    "    \"top\": {\"ref\": \"blanket\"},\n",
    "    \"part_changes\": {\n",
    "        \"breeding_zone\": {\"children\": {\"stiffener\": {\"type\": \"beer_box\"}}}\n",
    "    },\n",
    "}\n",
    "\n",
    "parser = SettingsParser(settings, skeleton, operate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a part change is made the entire component will be rebuilt. This is to ensure that there are not parameters/storage left over. In this example, as the blanket requires rebuilding, the part information will be updated within the parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = {\n",
    "    \"assembly\": {\n",
    "        \"class_str\": [\"bom_analysis.bom.Assembly\"],\n",
    "        \"params_name\": [\"assembly\"],\n",
    "    },\n",
    "    \"component\": {\n",
    "        \"class_str\": [\"bom_analysis.bom.Component\"],\n",
    "        \"params_name\": [\"component\"],\n",
    "    },\n",
    "    \"blanket\": {\n",
    "        \"inherits\": [\"assembly\"],\n",
    "        \"children\": {\n",
    "            \"breeding_zone\": {\"type\": \"breeding_pins\"},\n",
    "            \"manifold\": {\"type\": \"double_wall_mf\"},\n",
    "        },\n",
    "    },\n",
    "    \"breeding_pins\": {\"inherits\": [\"component\"]},\n",
    "    \"double_wall_mf\": {\"inherits\": [\"component\"]},\n",
    "}\n",
    "\n",
    "parameters = {\n",
    "    \"component\": {\"mass\": {\"var\": \"mass\", \"unit\": \"kg\", \"value\": None}},\n",
    "    \"assembly\": {\n",
    "        \"number_of_components\": {\n",
    "            \"var\": \"number_of_components\",\n",
    "            \"unit\": None,\n",
    "            \"value\": None,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "parser.parameters.update(parameters)\n",
    "parser.vertebrae.update(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, SettingsParser has no idea what beer_box is, therefore it has rebuilt the skeleton. This information can be supplied within settings by settings[\"parts\"][\"location\"] (defaults when from_file=True) or passed to the functions as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_components = {\n",
    "    \"beer_box\": {\n",
    "        \"inherits\": [\"component\"],\n",
    "        \"shape\": \"square\",\n",
    "        \"params_name\": [\"box_structure\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "new_parameters = {\n",
    "    \"box_structure\": {\n",
    "        \"NEW\": {\n",
    "            \"descr\": None,\n",
    "            \"name\": \"NEWparam\",\n",
    "            \"source\": \"Input\",\n",
    "            \"unit\": \"N/A\",\n",
    "            \"value\": None,\n",
    "            \"var\": \"NEW\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "parser.vertebrae.update(new_components)\n",
    "parser.parameters.update(new_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the information has been added to the parser, the skeleton can undergo the surgery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.surgery()\n",
    "pprint.pprint(parser.skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows how the skeleton can be modified to allow children to change. As in the previous example, the special strings (\"params_name\", \"inherits\"...) can be expanded on. The bones can then be expanded on by adding marrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Storage\n",
    "#### Other Storage Types\n",
    "The examples have already used the parameters storage types but the BOM analysis has a few others provided (external ones can be used, the \"class_str\" just requires definition.\n",
    "* DFClass - a wrapper for a pandas DataFrame\n",
    "* MaterialData - a wrapper for material properties (DataFrame input and CoolProps already wrapped)\n",
    "\n",
    "These can be specified by supplying adding to the skeleton. All storage types will be searched in supplied dictionaries when \"inherits\" is specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.vertebrae[\"double_wall_mf\"][\"key_coords\"] = {\"inherits\": [\"coordinates\"]}\n",
    "print(\"\\n\\n---Before Marrow Added---\\n\")\n",
    "pprint.pprint(parser.skeleton[\"manifold\"])\n",
    "\n",
    "storage = {\n",
    "    \"coordinates\": {\n",
    "        \"class_str\": [\"bom_analysis.base.DFClass\"],\n",
    "        \"desc\": \"a database of coordinates\",\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\\n---After Marrow Added---\\n\")\n",
    "parser.storage.update(storage)\n",
    "parser.surgery()\n",
    "pprint.pprint(parser.skeleton[\"manifold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inheritance for storage works in exactly the same way as children, therefore, there is the ability to stack/inherit from multiple dictionaries along a long chain.\n",
    "\n",
    "#### Modules\n",
    "Modules can be given requirements which means that particular required Storage Class/parameter/keys can be specified. In the example, say an FEA is required on the components, but storage may be DataFrame required for the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To mesh the requirements was for a node dataframe to be specified which has been automatically populated in the skeleton which the information being based to add_marrow - as with the above, this can happen automattically by supplying a location of the .json to the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_definition = {\n",
    "    \"meshing\": {\n",
    "        \"args\": [\"breeding_zone\", \"manifold\"],\n",
    "        \"run\": \"mesh\",\n",
    "        \"requirements\": {\n",
    "            \"breeding_zone\": {\"nodes\": {\"class_str\": [\"pandas.DataFrame\"]}},\n",
    "            \"manifold\": {\"nodes\": {\"class_str\": [\"pandas.DataFrame\"]}},\n",
    "        },\n",
    "    }\n",
    "}\n",
    "modules_to_run = {\"order\": {\"0\": \"meshing\"}}\n",
    "\n",
    "parser.update_settings({\"modules\": modules_to_run})\n",
    "\n",
    "parser.modules.update(module_definition)\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with everything, default values/materials can be loaded from a file and used to populate the skeleton. All that is required is the nested dictionary to the item which requires editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = {\n",
    "    \"manifold\": {\n",
    "        \"params\": {\"data\": {\"mass\": {\"value\": 100}}},\n",
    "        \"material\": {\"name\": \"steel\"},\n",
    "    }\n",
    "}\n",
    "parser.defaults.update(defaults)\n",
    "parser.surgery()\n",
    "\n",
    "pprint.pprint(parser.skeleton[\"manifold\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other changes works in exactly the same way but the changes can be specified directly in the settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials\n",
    "Materials was mentioned previously as a special input to the skeleton. It is still built like any other storage with the exception that there is a check for the materials in an order of databases contained within the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bom_analysis.base import BaseConfig as Config\n",
    "from bom_analysis.utils import Translator\n",
    "\n",
    "Config.define_config(config_path=\"./files/example_config.json\")\n",
    "Translator.define_translations(Config.translations)\n",
    "pprint.pprint(Config.materials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with everything convered \"class_str\" is a special key and contains the class which will define that material. The order defines the priority order for the materials - in the above example all materials will be searched for in CoolProps and if not returned, searched for in a DataFrame material wrapper.\n",
    "\n",
    "*Note that the \"translate_to\" string gives the translation used in the transalator covered in example 1.*\n",
    "\n",
    "Normally the materials are selected within add_marrow as a full build will supply \"inherits\" to the material so that it can inherit solid/fluid storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.update_config()\n",
    "material = parser.skeleton[\"manifold\"][\"material\"]\n",
    "parser.select_library(material)\n",
    "pprint.pprint(parser.skeleton[\"manifold\"][\"material\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this it is shown that CoolProps does not have eurofer so the data has been taken from the DataFrame library with the dataframe loaded from \"./files/CD-STEP-00824.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "The example given has modified the skeleton by altering the settings.\n",
    "\n",
    "It has shown the various types of special keys used to rebuild the skeleton, add_defaults, populate materials classes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open(Path(\"./example_Modifying_a_Skeleton_from_Settings.json\"), \"w\") as f:\n",
    "    json.dump(parser.skeleton, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
